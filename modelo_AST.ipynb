{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dbcb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install javalang\n",
    "%pip install simhash\n",
    "%pip install apted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf628e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, numpy as np, pandas as pd, javalang\n",
    "from simhash import Simhash\n",
    "from apted import APTED, Config                       # ← reemplazo de zss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from tensorflow.keras.layers import Input, Conv1D, GlobalMaxPooling1D, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62522aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SimHash\n",
    "def simhash_bits(code: str, nbits: int = 64) -> int:\n",
    "    tokens = code.strip().split()\n",
    "    return Simhash(tokens, f=nbits).value   # entero de nbits\n",
    "\n",
    "def simhash_sim(c1: str, c2: str, nbits: int = 64) -> float:\n",
    "    h1, h2 = simhash_bits(c1, nbits), simhash_bits(c2, nbits)\n",
    "    dist = bin(h1 ^ h2).count(\"1\")\n",
    "    return 1 - dist / nbits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb253a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def java_ast(code: str):\n",
    "    tree = javalang.parse.parse(code)\n",
    "    def to_node(node):\n",
    "        lbl = type(node).__name__\n",
    "        kids = []\n",
    "        for _, v in node:\n",
    "            if isinstance(v, javalang.ast.Node):\n",
    "                kids.append(to_node(v))\n",
    "            elif isinstance(v, list):\n",
    "                kids += [to_node(k) for k in v if isinstance(k, javalang.ast.Node)]\n",
    "        return Node(lbl, kids)\n",
    "    return to_node(tree)\n",
    "\n",
    "class Node:                    # nodo simple para APTED\n",
    "    __slots__ = (\"label\", \"children\")\n",
    "    def __init__(self, lbl, kids=None):\n",
    "        self.label = lbl\n",
    "        self.children = kids or []\n",
    "\n",
    "# Configuración Zhang‑Shasha\n",
    "class ZhangConfig(Config):\n",
    "    def rename(self, a, b):     return 0 if a.label == b.label else 1\n",
    "    def children(self, node):   return node.children\n",
    "    def insert(self, node):     return 1\n",
    "    def delete(self, node):     return 1\n",
    "\n",
    "def ast_sim(c1: str, c2: str) -> float:\n",
    "    t1, t2 = java_ast(c1), java_ast(c2)\n",
    "    dist   = APTED(t1, t2, ZhangConfig()).compute_edit_distance()\n",
    "    base   = max(t1.size if hasattr(t1,'size') else count_nodes(t1),\n",
    "                 t2.size if hasattr(t2,'size') else count_nodes(t2))\n",
    "    return 1 - dist / base\n",
    "\n",
    "def count_nodes(n):             # tamaño para normalizar\n",
    "    return 1 + sum(count_nodes(c) for c in n.children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d5f946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_feats(row):\n",
    "    try:\n",
    "        return pd.Series({\n",
    "            'simhash_sim': simhash_sim(row.code1_sanitized, row.code2_sanitized),\n",
    "            'ast_sim'    : ast_sim    (row.code1_sanitized, row.code2_sanitized)\n",
    "        })\n",
    "    except Exception as e:\n",
    "        # si algo falla (memoria, parseo, etc.) lo marcamos con -1\n",
    "        print(\"fallo en fila\", row.name, \"→\", e)\n",
    "        return pd.Series({'simhash_sim': -1.0, 'ast_sim': -1.0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec101335",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "val_df   = pd.read_csv(\"val.csv\")\n",
    "test_df  = pd.read_csv(\"test.csv\")\n",
    "\n",
    "for df_, tag in [(train_df,'train'), (val_df,'validation'), (test_df,'test')]:\n",
    "    df_[\"split\"] = tag\n",
    "df = pd.concat([train_df, val_df, test_df], ignore_index=True)\n",
    "assert {'code1_sanitized','code2_sanitized','code1_vecMark','code2_vecMark','result'}.issubset(df.columns)\n",
    "\n",
    "df[['simhash_sim','ast_sim']] = df.apply(pair_feats, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3f8e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_vecs(col, maxlen=200):\n",
    "    vecs = df[col].apply(lambda x: np.array(eval(x)))\n",
    "    return pad_sequences(vecs, maxlen=maxlen, padding='post', dtype='float32')\n",
    "\n",
    "MAX_LEN = 200\n",
    "x1 = np.expand_dims(pad_vecs(\"code1_vecMark\", MAX_LEN), -1)\n",
    "x2 = np.expand_dims(pad_vecs(\"code2_vecMark\", MAX_LEN), -1)\n",
    "f_vec = df[['simhash_sim','ast_sim']].values.astype('float32')\n",
    "y      = df.result.values\n",
    "splits = df.split.values\n",
    "\n",
    "sel = splits == 'train'\n",
    "x1_train,x2_train,f_train,y_train = x1[sel],x2[sel],f_vec[sel],y[sel]\n",
    "sel = splits == 'validation'\n",
    "x1_val,x2_val,f_val,y_val = x1[sel],x2[sel],f_vec[sel],y[sel]\n",
    "sel = splits == 'test'\n",
    "x1_test,x2_test,f_test,y_test = x1[sel],x2[sel],f_vec[sel],y[sel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31350f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def branch(inp_shape):\n",
    "    inp = Input(shape=inp_shape)\n",
    "    x   = Conv1D(128, 5, activation='relu', padding='same')(inp)\n",
    "    x   = GlobalMaxPooling1D()(x)\n",
    "    return inp, x\n",
    "\n",
    "in1, out1 = branch((MAX_LEN,1))\n",
    "in2, out2 = branch((MAX_LEN,1))\n",
    "in_feat   = Input(shape=(2,))\n",
    "feat_dense= Dense(32, activation='relu')(in_feat)\n",
    "\n",
    "merged = Concatenate()([out1, out2, feat_dense])\n",
    "x = Dense(128, activation='relu')(merged)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model([in1,in2,in_feat], output)\n",
    "model.compile(optimizer=Adam(1e-3), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdacab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit([x1_train,x2_train,f_train], y_train,\n",
    "          validation_data=([x1_val,x2_val,f_val], y_val),\n",
    "          epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140bec2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate([x1_test, x2_test, f_test], y_test)\n",
    "print(f\"\\nTest accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434bdc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate([x1_test,x2_test,f_test], y_test)\n",
    "print(f\"\\nTest accuracy: {acc:.4f}\")\n",
    "\n",
    "y_pred = (model.predict([x1_test,x2_test,f_test]) > 0.5).astype(int).flatten()\n",
    "print(\"\\nReporte de clasificación:\\n\",\n",
    "      classification_report(y_test, y_pred, target_names=[\"Original\",\"Plagiado\"]))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=[\"Original\",\"Plagiado\"])\n",
    "fig, ax = plt.subplots(figsize=(6,6)); disp.plot(ax=ax, cmap=\"Blues\", values_format='d')\n",
    "plt.title(\"Matriz de Confusión\"); plt.tight_layout(); plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
