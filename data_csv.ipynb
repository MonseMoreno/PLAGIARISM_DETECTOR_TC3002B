{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "base_path = 'IR-Plag-Dataset'\n",
    "output_csv = 'dataset.csv'\n",
    "rows = []\n",
    "\n",
    "def read_file(path):\n",
    "    with open(path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        return f.read().replace('\\n', '\\\\n').replace('\\r', '')\n",
    "\n",
    "for case in sorted(os.listdir(base_path)):\n",
    "    case_path = os.path.join(base_path, case)\n",
    "    if not os.path.isdir(case_path):\n",
    "        continue\n",
    "\n",
    "    dataset_name = 'IR-Plag'\n",
    "    original_path = os.path.join(case_path, 'original')\n",
    "    original_file = next(os.scandir(original_path)).path\n",
    "    original_code = read_file(original_file)\n",
    "    original_id = f'{case}-ORIG'\n",
    "\n",
    "    nonplag_path = os.path.join(case_path, 'non-plagiarized')\n",
    "    if os.path.exists(nonplag_path):\n",
    "        for folder in sorted(os.listdir(nonplag_path)):\n",
    "            folder_path = os.path.join(nonplag_path, folder)\n",
    "            if not os.path.isdir(folder_path):\n",
    "                continue\n",
    "            file_path = next(os.scandir(folder_path)).path\n",
    "            code = read_file(file_path)\n",
    "            file_id = f'{case}-NP-{folder}'\n",
    "            rows.append([f'{original_id}_{file_id}', original_id, original_code, file_id, code, 0, dataset_name])\n",
    "\n",
    "    plag_path = os.path.join(case_path, 'plagiarized')\n",
    "    if os.path.exists(plag_path):\n",
    "        for level in sorted(os.listdir(plag_path)):\n",
    "            level_path = os.path.join(plag_path, level)\n",
    "            for folder in sorted(os.listdir(level_path)):\n",
    "                folder_path = os.path.join(level_path, folder)\n",
    "                if not os.path.isdir(folder_path):\n",
    "                    continue\n",
    "                file_path = next(os.scandir(folder_path)).path\n",
    "                code = read_file(file_path)\n",
    "                file_id = f'{case}-{level}-{folder}'\n",
    "                rows.append([f'{original_id}_{file_id}', original_id, original_code, file_id, code, 1, dataset_name])\n",
    "\n",
    "with open(output_csv, 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f, quoting=csv.QUOTE_ALL)\n",
    "    writer.writerow(['id', 'idcode1', 'code1', 'idcode2', 'code2', 'result', 'dataset'])\n",
    "    writer.writerows(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar conplag al CSV\n",
    "import pandas as pd\n",
    "\n",
    "conplag_base = 'conplag_version_2/versions'\n",
    "conplag_code_dir = os.path.join(conplag_base, 'version_2')\n",
    "conplag_labels = os.path.join(conplag_base, 'labels.csv')\n",
    "\n",
    "df = pd.read_csv(conplag_labels)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    sub1 = row['sub1']\n",
    "    sub2 = row['sub2']\n",
    "    verdict = row['verdict']\n",
    "    codeid1 = str(sub1)\n",
    "    codeid2 = str(sub2)\n",
    "    folder = f'{codeid1}_{codeid2}'\n",
    "    folder_path = os.path.join(conplag_code_dir, folder)\n",
    "\n",
    "    file1_path = os.path.join(folder_path, f'{codeid1}.java')\n",
    "    file2_path = os.path.join(folder_path, f'{codeid2}.java')\n",
    "\n",
    "    if not os.path.exists(file1_path) or not os.path.exists(file2_path):\n",
    "        continue\n",
    "\n",
    "    code1 = read_file(file1_path)\n",
    "    code2 = read_file(file2_path)\n",
    "    pair_id = f'{codeid1}_{codeid2}'\n",
    "    result = int(verdict)\n",
    "    dataset_name = 'conplag_version_2'\n",
    "\n",
    "    rows.append([pair_id, codeid1, code1, codeid2, code2, result, dataset_name])\n",
    "\n",
    "with open(output_csv, 'a', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f, quoting=csv.QUOTE_ALL)\n",
    "    for row in rows:\n",
    "        if row[-1] == 'conplag_version_2':\n",
    "            writer.writerow(row)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
