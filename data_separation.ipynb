{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86591ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaños finales: 948, 298, 293\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "# cargar dataset\n",
    "df = pd.read_csv(\"dataset_Similarity_calculation.csv\")\n",
    "total_rows = len(df)\n",
    "\n",
    "# unión‑find para agrupar cada archivo en su componente\n",
    "parent = {}\n",
    "def find(x):\n",
    "    parent.setdefault(x, x)\n",
    "    if parent[x] != x:\n",
    "        parent[x] = find(parent[x])\n",
    "    return parent[x]\n",
    "\n",
    "def union(a, b):\n",
    "    ra, rb = find(a), find(b)\n",
    "    if ra != rb:\n",
    "        parent[rb] = ra\n",
    "\n",
    "for a, b in zip(df[\"idcode1\"], df[\"idcode2\"]):\n",
    "    union(a, b)\n",
    "\n",
    "# filas agrupadas por componente conexo\n",
    "comp_rows = defaultdict(list)\n",
    "for idx, (a, _) in enumerate(zip(df[\"idcode1\"], df[\"idcode2\"])):\n",
    "    comp_rows[find(a)].append(idx)\n",
    "\n",
    "components = list(comp_rows.items())\n",
    "random.Random(42).shuffle(components)  # reproducible\n",
    "\n",
    "# metas de tamaño para 60 / 20 / 20\n",
    "target_train = int(total_rows * 0.60)\n",
    "target_test  = int(total_rows * 0.20)\n",
    "target_val   = total_rows - target_train - target_test\n",
    "\n",
    "splits = {\"train\": [], \"test\": [], \"val\": []}\n",
    "split_sizes = {\"train\": 0, \"test\": 0, \"val\": 0}\n",
    "\n",
    "# asignar componentes al split con mayor cupo disponible\n",
    "for comp_id, rows in components:\n",
    "    remaining = {\n",
    "        \"train\": target_train - split_sizes[\"train\"],\n",
    "        \"test\":  target_test  - split_sizes[\"test\"],\n",
    "        \"val\":   target_val   - split_sizes[\"val\"],\n",
    "    }\n",
    "    candidates = [s for s, r in remaining.items() if r > 0] or [\"train\"]\n",
    "    chosen = max(candidates, key=lambda s: remaining[s])\n",
    "    splits[chosen].extend(rows)\n",
    "    split_sizes[chosen] += len(rows)\n",
    "\n",
    "# construir dataframes finales\n",
    "train_df = df.loc[splits[\"train\"]].reset_index(drop=True)\n",
    "test_df  = df.loc[splits[\"test\"] ].reset_index(drop=True)\n",
    "val_df   = df.loc[splits[\"val\"]  ].reset_index(drop=True)\n",
    "\n",
    "# verificación de que no haya archivos en más de un split\n",
    "train_codes = set(train_df[\"idcode1\"]).union(train_df[\"idcode2\"])\n",
    "test_codes  = set(test_df[\"idcode1\"]).union(test_df[\"idcode2\"])\n",
    "val_codes   = set(val_df[\"idcode1\"]).union(val_df[\"idcode2\"])\n",
    "\n",
    "assert train_codes.isdisjoint(test_codes)\n",
    "assert train_codes.isdisjoint(val_codes)\n",
    "assert test_codes.isdisjoint(val_codes)\n",
    "\n",
    "# guardar archivos\n",
    "train_df.to_csv(\"train.csv\", index=False, quoting=1)\n",
    "test_df.to_csv(\"test.csv\",  index=False, quoting=1)\n",
    "val_df.to_csv(\"val.csv\",   index=False, quoting=1)\n",
    "\n",
    "print(f\"Tamaños finales: {len(train_df)}, {len(test_df)}, {len(val_df)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
